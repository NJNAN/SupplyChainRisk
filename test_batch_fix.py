#!/usr/bin/env python3
"""
æµ‹è¯•æ‰¹å¤„ç†çš„maskå’Œbatchä¿®å¤
"""

import torch
from torch_geometric.data import Data, DataLoader
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from robustness import RobustnessEvaluator
from src.models.gnn_models import GATModel
import yaml

def test_batch_fix():
    """æµ‹è¯•æ‰¹å¤„ç†ä¿®å¤"""
    print("ğŸ§ª æµ‹è¯•æ‰¹å¤„ç†æ‰°åŠ¨ä¿®å¤...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå¤šä¸ªå›¾
    graphs = []
    for i in range(8):  # 8ä¸ªå›¾
        num_nodes = 10 + i  # ä¸åŒçš„èŠ‚ç‚¹æ•°
        x = torch.randn(num_nodes, 93, device=device)
        
        # åˆ›å»ºç®€å•çš„è¿é€šå›¾
        edge_index = []
        for j in range(num_nodes - 1):
            edge_index.extend([[j, j+1], [j+1, j]])
        edge_index = torch.tensor(edge_index, device=device).t()
        
        edge_attr = torch.randn(edge_index.size(1), 3, device=device)
        y = torch.randint(0, 2, (1,), device=device)
        
        graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
        graphs.append(graph)
    
    # åˆ›å»ºDataLoader
    data_loader = DataLoader(graphs, batch_size=4, shuffle=False)
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    evaluator = RobustnessEvaluator(config)
    
    # åˆ›å»ºæ¨¡å‹
    model = GATModel(
        input_dim=93,
        hidden_dim=64,
        num_layers=2,
        dropout=0.1,
        num_classes=2,
        heads=4
    ).to(device)
    
    model.eval()
    
    print("æµ‹è¯•æ‰¹å¤„ç†æ‰°åŠ¨...")
    with torch.no_grad():
        for batch_idx, batch in enumerate(data_loader):
            batch = batch.to(device)
            print(f"\næ‰¹æ¬¡ {batch_idx}:")
            print(f"  åŸå§‹: æ€»èŠ‚ç‚¹æ•°={batch.x.size(0)}, æ€»è¾¹æ•°={batch.edge_index.size(1)}")
            print(f"  æ‰¹æ¬¡å¤§å°: {batch.batch.max().item() + 1}")
            
            try:
                # æµ‹è¯•åŸºå‡†å‰å‘ä¼ æ’­
                outputs = model(batch)
                print(f"  åŸºå‡†è¾“å‡ºå½¢çŠ¶: {outputs.shape}")
                
                # æµ‹è¯•æ‰°åŠ¨
                for drop_rate in [0.2, 0.4]:
                    perturbed_batch = evaluator.perturb_graph(batch, drop_rate=drop_rate)
                    print(f"  æ‰°åŠ¨({drop_rate}): èŠ‚ç‚¹æ•°={perturbed_batch.x.size(0)}, è¾¹æ•°={perturbed_batch.edge_index.size(1)}")
                    
                    # æ£€æŸ¥batchä¿¡æ¯æ˜¯å¦ä¸€è‡´
                    if hasattr(perturbed_batch, 'batch') and perturbed_batch.batch is not None:
                        print(f"    batchå¤§å°: {perturbed_batch.batch.size(0)}, æœ€å¤§batchå€¼: {perturbed_batch.batch.max().item()}")
                        
                        # ç¡®ä¿batchå’ŒèŠ‚ç‚¹æ•°ä¸€è‡´
                        if perturbed_batch.batch.size(0) != perturbed_batch.x.size(0):
                            print(f"    âŒ batchå¤§å°ä¸åŒ¹é…: batch={perturbed_batch.batch.size(0)}, nodes={perturbed_batch.x.size(0)}")
                            continue
                    
                    # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
                    perturbed_outputs = model(perturbed_batch)
                    print(f"    æ‰°åŠ¨è¾“å‡ºå½¢çŠ¶: {perturbed_outputs.shape}")
                    print(f"    âœ… æ‰°åŠ¨ç‡ {drop_rate} æµ‹è¯•é€šè¿‡")
                
            except Exception as e:
                print(f"    âŒ æ‰¹æ¬¡ {batch_idx} æµ‹è¯•å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                return False
    
    print("\nğŸ‰ æ‰€æœ‰æ‰¹å¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    test_batch_fix()
