#!/usr/bin/env python3
"""
æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤çš„è„šæœ¬
"""

import torch
import torch.nn as nn
from torch_geometric.data import Data, DataLoader
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from robustness import RobustnessEvaluator
from src.models.gnn_models import GATModel, GCNModel, GraphSAGEModel
import yaml

def create_test_graph_data(batch_size=4, num_nodes=10, num_features=93):
    """åˆ›å»ºæµ‹è¯•å›¾æ•°æ®"""
    graphs = []
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    for _ in range(batch_size):
        # èŠ‚ç‚¹ç‰¹å¾
        x = torch.randn(num_nodes, num_features, device=device)
        
        # è¾¹ç´¢å¼• - åˆ›å»ºä¸€ä¸ªç®€å•çš„è¿é€šå›¾
        edge_index = []
        for i in range(num_nodes - 1):
            edge_index.extend([[i, i+1], [i+1, i]])  # åŒå‘è¾¹
        edge_index = torch.tensor(edge_index, dtype=torch.long, device=device).t()
        
        # è¾¹ç‰¹å¾
        edge_attr = torch.randn(edge_index.size(1), 3, device=device)
        
        # å›¾æ ‡ç­¾
        y = torch.randint(0, 2, (1,), device=device)
        
        graph = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)
        graphs.append(graph)
    
    return graphs

def test_device_consistency():
    """æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§"""
    print("ğŸ§ª æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½é…ç½®
    with open('config.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # åˆ›å»ºé²æ£’æ€§è¯„ä¼°å™¨
    evaluator = RobustnessEvaluator(config)
    
    # åˆ›å»ºæµ‹è¯•å›¾æ•°æ®
    test_graphs = create_test_graph_data(batch_size=8)
    test_loader = DataLoader(test_graphs, batch_size=2, shuffle=False)
    
    # åˆ›å»ºç®€å•çš„GNNæ¨¡å‹ç”¨äºæµ‹è¯•
    model = GATModel(
        input_dim=93,
        hidden_dim=64,
        num_layers=2,
        dropout=0.1,
        num_classes=2,
        heads=4
    ).to(device)
    
    print("âœ… æµ‹è¯•å›¾æ‰°åŠ¨...")
    try:
        # æµ‹è¯•å›¾æ‰°åŠ¨
        for batch in test_loader:
            batch = batch.to(device)
            print(f"åŸå§‹æ‰¹æ¬¡è®¾å¤‡: x={batch.x.device}, edge_index={batch.edge_index.device}")
            
            # æµ‹è¯•èŠ‚ç‚¹ä¸¢å¼ƒ
            perturbed_batch = evaluator.perturb_graph(batch, drop_rate=0.2)
            print(f"æ‰°åŠ¨åè®¾å¤‡: x={perturbed_batch.x.device}, edge_index={perturbed_batch.edge_index.device}")
            
            # æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
            model.eval()
            with torch.no_grad():
                outputs = model(perturbed_batch)
                print(f"æ¨¡å‹è¾“å‡ºè®¾å¤‡: {outputs.device}")
            
            break  # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
        
        print("âœ… å›¾æ‰°åŠ¨æµ‹è¯•é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ å›¾æ‰°åŠ¨æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    print("âœ… æµ‹è¯•å™ªå£°æ·»åŠ ...")
    try:
        # åˆ›å»ºåºåˆ—æ•°æ®æµ‹è¯•å™ªå£°æ·»åŠ 
        seq_data = torch.randn(4, 24, 93, device=device)
        noisy_data = evaluator.add_noise(seq_data, noise_level=0.1)
        print(f"åŸå§‹æ•°æ®è®¾å¤‡: {seq_data.device}")
        print(f"å™ªå£°æ•°æ®è®¾å¤‡: {noisy_data.device}")
        
        print("âœ… å™ªå£°æ·»åŠ æµ‹è¯•é€šè¿‡ï¼")
    except Exception as e:
        print(f"âŒ å™ªå£°æ·»åŠ æµ‹è¯•å¤±è´¥: {str(e)}")
        return False
    
    print("ğŸ‰ æ‰€æœ‰è®¾å¤‡ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ï¼")
    return True

def test_robustness_evaluation():
    """æµ‹è¯•é²æ£’æ€§è¯„ä¼°"""
    print("ğŸ§ª æµ‹è¯•é²æ£’æ€§è¯„ä¼°...")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # åŠ è½½é…ç½®
        with open('config.yaml', 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        evaluator = RobustnessEvaluator(config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_graphs = create_test_graph_data(batch_size=16)
        test_loader = DataLoader(test_graphs, batch_size=4, shuffle=False)
        
        # åˆ›å»ºæ¨¡å‹
        model = GraphSAGEModel(
            input_dim=93,
            hidden_dim=64,
            num_layers=2,
            dropout=0.1,
            num_classes=2
        ).to(device)
        
        # æµ‹è¯•é²æ£’æ€§è¯„ä¼°
        results = evaluator.evaluate_model_robustness(model, test_loader, 'graphsage', 'drop')
        
        print(f"åŸºå‡†å‡†ç¡®ç‡: {results['baseline_accuracy']:.4f}")
        print(f"åŸºå‡†F1åˆ†æ•°: {results['baseline_f1']:.4f}")
        print(f"é²æ£’æ€§æ›²çº¿æ•°é‡: {len(results['robustness_curves'])}")
        
        print("âœ… é²æ£’æ€§è¯„ä¼°æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ é²æ£’æ€§è¯„ä¼°æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("ğŸ”§ å¼€å§‹è®¾å¤‡ä¸€è‡´æ€§ä¿®å¤æµ‹è¯•...")
    print("=" * 60)
    
    # æµ‹è¯•è®¾å¤‡ä¸€è‡´æ€§
    success1 = test_device_consistency()
    
    print("\n" + "=" * 60)
    
    # æµ‹è¯•é²æ£’æ€§è¯„ä¼°
    success2 = test_robustness_evaluation()
    
    print("\n" + "=" * 60)
    
    if success1 and success2:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®¾å¤‡ä¸€è‡´æ€§é—®é¢˜å·²ä¿®å¤ã€‚")
        exit(0)
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥ã€‚")
        exit(1)
